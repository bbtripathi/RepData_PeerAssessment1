rnorm(n, mean, sd)
}
noise(5,1,2)
noise(1:5,1:5,2)
mapply(noise, 1:5,1:5,2)
log(-1)
printmessage <- function (x) {}
printmessage <- function (x) {
if (x>0)
print ("x is greater than zero")
else
print("x is less than zero")
invisible(x)
}
printmessage(-1)
printmessage(5)
printmessage(a)
printmessage(z)
print("x is less than zero")
printmessage(NA)
printmessage(1)
x
mean(h)
traceback()
clear()
clr
clr()
lm(h ~ g)
traceback()
debug(lm)
lm(h ~ g)
x
y
options(error = recover)
read.csv("nosuchfile")
quit()
library(datsets)
library(datasets)
data(iris)
?iris
mean(iris$Sepal.Length)
colMeans(iris)
lapply(iris, mean)
apply(iris, 2, mean)
apply(iris[, 1:4], 2, mean)
apply(iris, 1, mean)
rowMeans(iris[, 1:4])
data(mtcars)
?mtcars
apply(mtcars, 2, mean)
mean(mtcars$mpg, mtcars$cyl)
split(mtcars, mtcars$cyl)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
sapply(split(mtcars$hp, mtcars$cyl), mean)
x <- sapply(split(mtcars$hp, mtcars$cyl), mean)
x
x[x==8] - x[x==4]
name(x)
names(x)
x["4"]
x["8"] - x["4"]
debug(ls)
ls
ls()
q
quit
exit
q
quit()
q
q
Q()
quit
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
q
undebug(ls)
quit
q()
library(datasets)
data(iris)
?iris
lapply(iris, mean)
sapply(iris, mean)
split(iris, iris$Species)
sapply(split(iris, iris$Species), mean)
s <- split(iris, iris$Species)
lapply(s, function(x) colMeans(x[, c("Sepal.Length")]))
lapply(s, colMeans(iris$Sepal.Length))
s
lapply(s, function(x) colMeans(x[, c("Sepal.Length", "Petal.Width")]))
colMeans(iris)
rowMeans(iris[, 1:4])
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
data(mtcars)
?mtcars
with(mtcars, tapply(mpg, cyl, mean))
apply(mtcars, 2, mean)
split(mtcars, mtcars$cyl)
x <- with(mtcars, tapply(mpg, cyl, mean))
x
x["8"] - x["4"]
q()
df1 = data.frame(id=sample(1:10),x=rnorm(10))
df2 = data.frame(id=sample(1:10),x=rnorm(10))
library(plyr)
arrange(join(df1,df2),id)
df2 = data.frame(id=sample(1:10),y=rnorm(10))
arrange(join(df1,df2),id)
df3 = data.frame(id=sample(1:10),z=rnorm(10))
dfList=list(df1,df2,df3)
join_all(dfList)
fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileurl, destfile = "hid.csv")
hiddata <- read.csv("hid.csv")
head(hiddata, n=3)
head(hiddata$ACR)
hiddata$ACR[hiddata$ACR == 3]
hiddata[(hiddata$ACR == 3 & hiddata$AGS == 6),]
x <- hiddata[(hiddata$ACR == 3 & hiddata$AGS == 6),]
head(x, n=3)
x[c(x$ACR, x$AGS),]
sum(is.na(hiddata$ACR))
x <- hiddata[(hiddata$ACR == 3 & hiddata$AGS == 6),]
which(x)
x <- (hiddata$ACR == 3 & hiddata$AGS == 6)
which(x)
install.packages("jpeg", lib="E:/R/R-3.1.0/library")
library(jpeg)
jpgurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(jpgurl, destfile="jeff.jpg")
?readjpeg
?read.jpeg
??jpeg
jeff <- readJPEG("jeff.jpg", TRUE)
?system.file
?readJPEG
img <- readJPEG("jeff.jpg")
download.file(jpgurl, destfile="jeff.jpg")
img <- readJPEG("jeff.jpg")
img.n <- readJPEG("jeff.jpg", TRUE)
if (exists("rasterImage")) { # can plot only in R 2.11.0 and higher
plot(1:2, type='n')
rasterImage(img, 1.2, 1.27, 1.8, 1.73)
rasterImage(img.n, 1.5, 1.5, 1.9, 1.8)
}
quantile(img.n, probs=c(0.3, 0.8))
pwd
getwd()
img.n <- readJPEG("jeff1.jpg", TRUE)
quantile(img.n, probs=c(0.3, 0.8))
gdpurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
cntryurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(gdpurl, destfile = "gdp.csv")
download.file(cntryurl, destfile = "cntry.csv")
gdp <- read.csv("gdp.csv")
cntry <- read.csv("cntry.csv")
names(gdp)
names(cntry)
head(gdp, n=3)
head(cntry, n=3)
mergedata = merge(gdp, cntry, by.x = "X", by.y="CountryCode")
head(mergedata, n=3)
mergedata = merge(gdp, cntry, by.x = "X", by.y="CountryCode", all=TRUE)
gdp <- read.csv("gdp.csv")
names(cntry)
cntry <- read.csv("cntry.csv")
names(cntry)
names(gdp)
mergedata = merge(gdp, cntry, by.x = "Country", by.y="CountryCode")
mergedata = merge(gdp, cntry, by.x = "Country", by.y="CountryCode", all=TRUE)
tail(mergedata)
View(mergedata)
library(plyr)
arrange(mergedata, desc(Ranking))
sortdata <- arrange(mergedata, desc(Ranking))
sortdata[,c(sortdata$Country, sortdata$Ranking)]
names(sortdata)
sortdata[,1:2]
head(sortdata[,1:3], n=15)
df <- as.data.frame(mergedata)
summary(df)
split(mergedata$Ranking, mergdata$Income.Group)
split(mergedata$Ranking, mergedata$Income.Group)
spIns = split(mergedata$Ranking, mergedata$Income.Group)
spravg = lapply(spIns, average)
spravg = lapply(spIns, avg)
spravg = lapply(spIns, mean)
spravg
spravg = lapply(spIns, mean, is.na=FALSE)
spravg
mergedata <= mergedata[1:190,]
x <= mergedata[1:190,]
warnings()
x = mergedata[1:190,]
spIns = split(x$Ranking, x$Income.Group)
spravg = lapply(spIns, mean, is.na=FALSE)
spravg
spravg = lapply(spIns, mean, is.na=TRUE)
spravg
spIns = split(mergedata$Ranking, mergedata$Income.Group)
spravg = lapply(spIns, mean)
spravg
?mean
spravg = lapply(spIns, mean, na.rm=TRUE)
spravg
quantile(mergedata$Ranking, probs=c(0.2,0.4,0.6,0.8,1), na.rm=TRUE)
quantile(mergedata$Ranking,na.rm=TRUE)
names(mergedata)
table(mergedata$Income.group, mergedata$Ranking)
length(mergedata$Income.group)
length(mergedata$"Income.group")
?quantile
quantile(mergedata$Ranking, probs=c(0.2,0.4,0.6,0.8,1), na.rm=TRUE)
mergedata$Income.group
table(mergedata[,6], mergedata$Ranking)
?xtabs
table(df$Income.group, df$Ranking)
table(df[,6], df$Ranking)
mergedata$RankingGroups = cut(mergedata[,6],breaks=quantile(mergedata$Ranking))
mergedata$RankingGroups = cut(mergedata$Ranking,breaks=quantile(mergedata$Ranking))
mergedata$RankingGroups = cut(mergedata$Ranking,breaks=quantile(mergedata$Ranking, na.rm=TRUE))
table(mergedata$RankingGroups,mergedata[,6])
mergedata$RankingGroups = cut(mergedata$Ranking,breaks=quantile(mergedata$Ranking, probs=c(0.2,0.4,0.6,0.8,1.0), na.rm=TRUE))
table(mergedata$RankingGroups,mergedata[,6])
mergedata$RankingQuantiles = cut(mergedata$Ranking,breaks=quantile(mergedata$Ranking, probs=c(0.2,0.4,0.6,0.8,1.0), na.rm=TRUE))
table(mergedata$RankingQuantiles,mergedata[,6])
library(Hmisc)
cut2(mergedata$Ranking, g=5)
cut2(mergedata$Ranking, g=4)
cut2(mergedata$Ranking, g=5)
mergedata$RQ <- cut2(mergedata$Ranking, g=4)
table(mergedata$RQ,mergedata[,6])
mergedata$RQ <- cut2(mergedata$Ranking, g=5)
table(mergedata$RQ,mergedata[,6])
q()
gdp <- read.csv("gdp.csv")
fed <- read.csv("cntry.csv")
head(gdp,2)
tail(gdp,2)
head(fed,2)
tail(fed,2)
names(fed)
names(gdp)
names(fed)
md <- merge(fed, gdp, by.x="CountryCode", by.y="Country", all=TRUE)
?merge
md <- merge(fed, gdp, by.x="CountryCode", by.y="Country", all=FALSE)
gdp <- read.csv("gdp.csv")
fed <- read.csv("cntry.csv")
dflist <- list(gdp,fed)
join_all(dflist)
library(plyr)
join_all(dflist)
df <- join_all(dflist)
?join_all
df <- join_all(dflist, type="inner")
df <- join_all(dflist, type="inner",match="first")
View(df)
View(df)
dflist <- list(fed,gdp)
df <- join_all(dflist, type="inner",match="first")
?sort
arrange(df,desc(Ranking))
quit()
quit()
q()
q()
x <- rnorm(100)
hist(x)
y <- rnorm(100)
plot(x,y)
z <- rnorm(100)
plot(x,z)
plot(x,y)
par(mar=c(2,2,2,2))
plot(x,y)
par(mar=c(4,4,2,2))
plot(x,y)
plot(x,y, pch=20)
plot(x,y, pch=19)
plot(x,y, pch=2)
plot(x,y, pch=4)
plot(x,y, pch=12)
example(points)
plot(x,y, pch=20)
x <- rnorm(100)
y <- rnorm(100)
plot(x,y, pch=20)
title("BT plot")
text(-2, -2, "label")
legend("topleft", legend = "Data", pch = 20)
fit <- lm (y - x)
fit <- lm (y ~ x)
abline(fit)
abline(fit, lwd = 3, col = "blue")
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
legend("topright", legend = "Data", pch = 20)
abline(fit, lwd = 3, col = "red")
z <- rpois(100,2)
par(mfrow = c(2,1))
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
plot(x, z, xlab = "Weight", ylab = "Height", main="scatter", pch = 19)
par("mar")
par(mar = c(2,2,1,2))
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
plot(x, z, xlab = "Weight", ylab = "Height", main="scatter", pch = 19)
par(mfrow = c(1,2))
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
plot(x, z, xlab = "Weight", ylab = "Height", main="scatter", pch = 19)
par(mar = c(4,4,2,2))
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
plot(x, z, xlab = "Weight", ylab = "Height", main="scatter", pch = 19)
par(mfrow = c(2,2))
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
plot(x, z, xlab = "Weight", ylab = "Height", main="scatter", pch = 19)
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
plot(x, z, xlab = "Weight", ylab = "Height", main="scatter", pch = 19)
par(mfcol = c(2,2))
plot(x, z, xlab = "Weight", ylab = "Height", main="scatter", pch = 19)
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
plot(x, z, xlab = "Weight", ylab = "Height", main="scatter", pch = 19)
plot(x, y, xlab = "Weight", ylab = "Height", main="scatter", pch = 20)
par(mfcol = c(1,1))
y <- x + rnorm(100)
g <- g(2,50, labels = c("Male","Female"))
g <- gl(2,50, labels = c("Male","Female"))
str(g)
plot(x,y)
plot(x,y, type ="n")
points(x[g == "Male"],y[g=="Male"], col="green")
points(x[g == "Feale"],y[g=="Feale"], col="blue")
points(x[g == "Female"],y[g=="Female"], col="blue")
?Devices
library(datasets)
with(faithful, plot(eruptions, waiting))
title(main = "Old data")
pdf(file = "myplot.pdf")
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser Data")
dev.off()
with(faithful, plot(eruptions, waiting))
title(main = "Old Faithful Geyser Data")
dev.copy(png, file="geyserplot.png")
dev.off()
install.packages("knitr")
quit
q()
ilbrary(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
str(spm[, 1:5])
str(spam[, 1:5])
q()
library(kernlab)
data(spam)
set.seed(3435)
trainIndicator = rbinom(4601, size =1, prob = 0.5)
table(trainIndicator)
trainSpam = spam[trainIndicator ==1, ]
testSpam = spam[trainIndicator ==0, ]
names(trainSpam)
head(trainSpam, 5)
table(trainSpam$type)
plot(trainSpam$capitalAve~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam[, 1:4] + 1)
)
hCluster = hclust(dist(t(trainSpam[, 1:57])))
plot(hCluster)
hClusterUpdated = hclust(dist(t(trainSpam[, 1:55])))
plot(hClusterUpdated)
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
## Which predictor has minimum cross-validated error?
names(trainSpam)[which.min(cvError)]
cvError
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
## Get predictions on the test set
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
## Classify as `spam' for those with prob > 0.5
predictedSpam[predictionModel$fitted > 0.5] = "spam"
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
table(predictedSpam, testSpam$type)
(61 + 458)/(1346 + 458 + 61 + 449)
library(kernlab)
data(spam)
# Perform the subsampling
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)
table(trainIndicator)
trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
names(trainSpam)
head(trainSpam)
table(trainSpam$type)
plot(trainSpam$capitalAve ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam[, 1:4] + 1))
hCluster = hclust(dist(t(trainSpam[, 1:57])))
plot(hCluster)
hClusterUpdated = hclust(dist(t(log10(trainSpam[, 1:55] + 1))))
plot(hClusterUpdated)
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55) {
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
names(trainSpam)[which.min(cvError)]
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
## Get predictions on the test set
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam[predictionModel$fitted > 0.5] = "spam"
table(predictedSpam, testSpam$type)
(61 + 458)/(1346 + 458 + 61 + 449)
library(markdown)
library(slidify)
install.packages("slidify")
install.packages("slidify")
library(datasets);
data(airquality);
summary(airquality);
pairs(airquality)
fit <- lm(Ozone ~ Wind + Solar.R + Temp, data ~ airquality)
names(airquality)
?lm
fit <- lm(Ozone ~ Wind + Solar.R + Temp, data ~ airquality)
fit <- ln(Ozone ~ Wind + Solar.R + Temp, data ~ airquality)
fit <- lm(Ozone ~ Wind + Solar.R + Temp, data ~ airquality)
fit <- lm(Ozone ~ Wind, data ~ airquality)
setwd("C:/Users/tbharat/RepData_PeerAssessment1")
?impute
library(Hmisc)
?impute
age <- c(1,2,NA,4)
age.i <- impute(age)
age.i <- impute(age, mean)
